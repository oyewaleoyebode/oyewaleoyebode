# About Me

I’m Oyebode Oluwatobi Oyewale, a PhD student at the Cyber Resilience Laboratory, NAIST (Japan). My research focuses on voice biometrics and the design of secure speaker verification systems. I work at the intersection of artificial intelligence and cybersecurity, with a strong emphasis on practical deployment for mobile banking and financial security in underserved and low-resource environments.


## Research Projects
---
### Optimizing Voice Biometric Verification in Banking 

Biometric verification is increasingly important for secure identity authentication in banking. While fingerprints, facial recognition, and iris scanning are widely used, voice biometrics stands out as a promising solution due to its convenience, accessibility, and non-intrusive nature.

A key challenge, however, lies in the variability of voice data. Differences in device hardware, microphone quality, and recording environments introduce inconsistencies that can degrade system performance. For mobile banking, where customers often rely on low-end devices in noisy environments, this variability threatens both security and usability.

This project tackles these issues by combining machine learning methods with speech enhancement techniques to improve the reliability and accuracy of voice biometric verification.

**> View Repositories https://github.com/oyewaleoyebode/Optimizing-Voice-Biometric-Verification-in-Banking-with-Machine-Learning-for-Speaker-Identification**

### Real-Time Speaker Identification System  

Mobile banking has boosted financial inclusion, but reliance on basic devices without biometric security exposes users to risks of fraud and unauthorized access. This project presents a lightweight speaker identification system that uses voice biometrics to confirm the user’s identity in real time, even if their PIN is compromised.

The system leverages Whisper-large-v3 and ECAPA-TDNN for fused embeddings, ensuring high accuracy, robustness, and real-time performance on low-end devices. Integrated liveness detection strengthens defense against spoofing attacks. Evaluations show 99.59% accuracy, 99.62% precision, and an EER of 0.0017, demonstrating its practicality in constrained environments.

**> View Repositories https://github.com/oyewaleoyebode/Speaker-Identification-for-Low-End-Devices-A-Secure-Voice-Biometric-Solution-for-Mobile-Banking**

### Degradation-Aware Verification Framework  

Proposed and implemented **Predictive Degradation Threshold Modeling (PDTM)**, **which forecasts verification risks based on SNR, MFCC variability, and previous outcomes**. This enables adaptive security controls like liveness detection and fallback mechanisms.

**> Repositories Coming Soon**



## Dataset Creation: 

---
### SecureVoice50

**license: cc-by-4.0**

This paper introduces a **speech dataset** developed to advance research in **speaker identification** and **voice biometric verification**, particularly in the context of **mobile banking** and other security-sensitive applications. 

The dataset comprises recordings from **50 participants** with diverse linguistic and cultural backgrounds and varying levels of English proficiency. Each participant provided voice samples across multiple devices, including low-end smartphones, in-call scenarios, and external microphones, recorded in both indoor and outdoor environments to reflect real-world usage conditions.

**> View Repositories https://github.com/oyewaleoyebode/SecureVoice50-A-Multi-Device-Multi-Environment-Speech-Dataset-for-Secure-Speaker-Verification**

### A Pilot Speech Corpus for Studying Device and Environmental Variability in Voice Biometrics

**license: cc-by-4.0**

This dataset contains 480 recordings from 12 participants, collected across multiple devices (Samsung A04s, OnePlus Nord, iPhone 15 Pro, USB condenser mic) and in both indoor and outdoor conditions.

It captures cross-device and cross-environment variability to support research on speech enhancement, speaker identification, and speaker verification, enabling the development of more robust and secure voice biometric systems.

**>View Repositories https://github.com/oyewaleoyebode/A-Pilot-Speech-Corpus-for-Studying-Device-and-Environmental-Variability-in-Voice-Biometrics**


## Publications
---

O. Oluwatobi Oyewale, Y. Taenaka, and Y. Kadobayashi, 
**"Speaker Identification for Low-End Devices: A Secure Voice Biometric Solution for Mobile Banking,"**
*2025 11th IEEE International Conference on Privacy Computing and Data Security (PCDS),*
Hakodate, Japan, 2025, pp. 80-87, 
DOI: [10.1109/PCDS65695.2025.00020](https://doi.org/10.1109/PCDS65695.2025.00020)

O. O. Oyewale, M. D. Hossain, Y. Taenaka, and Y. Kadobayashi,  
**"Optimizing Voice Biometric Verification in Banking with Machine Learning for Speaker Identification,"**  
*Proceedings of the 2024 IEEE 29th Asia Pacific Conference on Communications (APCC)*,  
Bali, Indonesia, pp. 377–384, 2024.  
DOI: [10.1109/APCC62576.2024.10768085](https://doi.org/10.1109/APCC62576.2024.10768085)  

O. O. Oyewale,  
**"A Pilot Speech Corpus for Studying Device and Environmental Variability in Voice Biometrics,"**  
*Figshare*, 2025.  
DOI: [10.6084/m9.figshare.30039037](https://doi.org/10.6084/m9.figshare.30039037)  

Oyebode, O. (2025), 
**"SecureVoice50: A Multi-Device, Multi-Environment Speech Dataset for Robust and Secure Speaker Verification,"**
*Zenodo*, 2025. 
DOI: [10.5281/zenodo.17184012](https://doi.org/10.5281/zenodo.17184012)

## Tools & Technologies I Use

- Voice Models: Whisper, ECAPA-TDNN, Wav2Vec2  
- Languages: Python (main), JavaScript, Shell scripting  
- Libraries: PyTorch, Hugging Face Transformers, SpeechBrain, Scikit-learn, Librosa  
- Workflow: Google Colab, Jupyter, VS Code, Git/GitHub  
- Deployment: FastAPI, Streamlit, REST APIs for voice-based access

---

## Let's Connect

- LinkedIn: [linkedin.com/in/oyebode-oluwatobi-oyewale-583114179](https://www.linkedin.com/in/oyebode-oluwatobi-oyewale-583114179)  
- Website: [https://sites.google.com/view/oyebodeoluwatobi/about](https://sites.google.com/view/oyebodeoluwatobi/about)

---

## Collaboration & Interests

I'm open to:

- Research collaborations in biometric security and speech AI  
- Consulting on secure voice systems for financial and identity platforms  
- PhD academic partnerships focused on privacy-preserving voice technologies

##Contact: Feel free to message me on LinkedIn for collaboration, research, or speaking opportunities.


Feel free to reach out.

